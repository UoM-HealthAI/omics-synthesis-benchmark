# ACTIVA模型架构详解与可视化

## 模型整体架构图

```
单细胞RNA数据 (基因表达矩阵)
           │
           ▼
    ┌─────────────────┐
    │   数据预处理     │
    │ (归一化、标准化) │
    └─────────────────┘
           │
           ▼
┌──────────────────────────────────────────────────────────┐
│                    ACTIVA 模型                           │
│                                                          │
│  ┌─────────────┐           ┌─────────────┐              │
│  │  编码器      │  潜在空间  │  解码器      │              │
│  │ (Encoder)   │ --------> │ (Decoder)   │              │
│  │             │  (z-dim)  │             │              │
│  └─────────────┘           └─────────────┘              │
│        │                         │                      │
│        │                         │                      │
│        ▼                         ▼                      │
│  ┌─────────────┐           ┌─────────────┐              │
│  │  μ (均值)    │           │ 重构数据     │              │
│  │  σ (方差)    │           │ (基因表达)   │              │
│  └─────────────┘           └─────────────┘              │
└──────────────────────────────────────────────────────────┘
           │                         │
           │                         │
           ▼                         ▼
┌─────────────────┐         ┌─────────────────┐
│   分类器模块     │         │   损失计算       │
│ (Classifier)    │         │                 │
│                 │         │ • 重构损失       │
│ 预测细胞类型     │         │ • KL散度损失     │
│                 │         │ • 分类损失       │
└─────────────────┘         │ • 对抗损失       │
                            └─────────────────┘
```

## 三个关键组件详解

### 1. 变分自编码器 (VAE) 组件

```
输入数据 (X) ────────────► 编码器 ────────────► 潜在空间 (Z)
                                                    │
                                                    ▼
重构数据 (X') ◄────────── 解码器 ◄────────────── 采样 ~ N(μ,σ²)
```

**作用**：
- **编码器**：将高维基因表达数据压缩到低维潜在空间
- **解码器**：从潜在表示重构原始数据
- **潜在空间**：学习数据的紧凑表示，便于生成新样本

### 2. 分类器 (Classifier) 组件

```
基因表达数据 ────────────► 分类器 ────────────► 细胞类型概率
(原始/重构)                                    [0.8, 0.1, 0.05, 0.05]
                                              ↓
                                           预测类别
                                          (如：T细胞)
```

**作用**：
- **细胞类型识别**：判断细胞属于哪种类型
- **条件约束**：确保生成的数据保持生物学一致性
- **质量控制**：验证重构数据是否保持原始细胞类型特征

### 3. 对抗训练机制

```
真实数据 ────────────► 编码器 ────────────► 解码器 ────────────► 重构数据
   │                                                              │
   ▼                                                              ▼
分类器(真实) ◄─────────────────── 分类一致性损失 ──────────────► 分类器(重构)
```

## 三阶段训练详解

### 阶段1：分类器预训练 (Epochs 1-5)

```
目标: 训练一个准确的细胞类型分类器

输入：真实单细胞数据 + 细胞类型标签
         │
         ▼
    ┌─────────────┐
    │   分类器     │ ─────► 预测概率
    │             │
    └─────────────┘
         │
         ▼
    交叉熵损失 = -Σ y_true * log(y_pred)

优化目标：min CrossEntropyLoss(真实标签, 预测标签)
```

**为什么需要预训练分类器？**
- 为后续阶段提供可靠的细胞类型判断能力
- 建立生物学约束的基础
- 确保生成数据的细胞类型一致性

### 阶段2：VAE预训练 (Epochs 6-10)

```
目标: 学习数据的基本表示和重构能力

输入数据 (X)
    │
    ▼
┌─────────────┐
│   编码器     │ ─────► μ, σ (潜在分布参数)
└─────────────┘           │
                          ▼
                    采样 z ~ N(μ, σ²)
                          │
                          ▼
                  ┌─────────────┐
                  │   解码器     │ ─────► 重构数据 (X')
                  └─────────────┘

损失函数:
L_VAE = L_reconstruction + β * L_KL

其中:
• L_reconstruction = ||X - X'||² (重构误差)
• L_KL = KL(q(z|X) || p(z)) (KL散度正则化)
```

**为什么需要VAE预训练？**
- 学习数据的基本表示能力
- 建立潜在空间的合理结构
- 为后续对抗训练提供稳定的基础

### 阶段3：完整ACTIVA训练 (Epochs 11-200)

```
目标: 结合对抗训练和条件约束，生成高质量条件数据

复杂的多目标优化:

编码器损失:
L_E = α₁ * L_margin + α₂ * (L_classification + L_reconstruction)

解码器损失:
L_G = α₁ * 0.5 * (L_rec_kl + L_fake_kl)

其中:
• L_margin: 边际损失 (对抗训练)
• L_classification: 分类一致性损失
• L_reconstruction: 重构损失
• L_rec_kl, L_fake_kl: KL散度损失
```

## 优化目标的生物学意义

### 1. 重构损失 (Reconstruction Loss)
```
目标: min ||X_original - X_reconstructed||²
意义: 确保生成的数据在基因表达层面与原始数据相似
```

### 2. KL散度损失 (KL Divergence Loss)
```
目标: min KL(q(z|X) || N(0,I))
意义: 使潜在表示遵循标准正态分布，便于随机采样生成新数据
```

### 3. 分类一致性损失 (Classification Consistency Loss)
```
目标: min CrossEntropy(Classifier(X_real), Classifier(X_reconstructed))
意义: 确保重构数据保持原始细胞的生物学身份
```

### 4. 边际损失 (Margin Loss)
```
目标: 平衡生成器和判别器的对抗训练
意义: 提高生成数据的真实性和多样性
```

## 条件生成的工作流程

```
Step 1: 细胞类型条件输入
细胞类型 = "T细胞"

Step 2: 潜在空间采样
z ~ N(0, I)  # 从标准正态分布采样

Step 3: 条件解码
X_generated = Decoder(z, cell_type_condition)

Step 4: 质量验证
predicted_type = Classifier(X_generated)
assert predicted_type == "T细胞"  # 确保生成正确类型

Step 5: 输出
生成的T细胞基因表达数据
```

## 关键超参数的作用

```
• zdim (128): 潜在空间维度
  - 更高维度 → 更丰富的表示能力，但计算复杂
  - 更低维度 → 更紧凑的表示，但可能丢失信息

• alpha_1 (1.0): KL损失权重
  - 控制潜在空间的规整程度

• alpha_2 (0.05): 重构和分类损失权重
  - 平衡重构质量和分类一致性

• m_plus (150.0): 边际参数
  - 控制对抗训练的强度
```

## 实际应用场景

1. **数据增强**：为稀少细胞类型生成更多样本
2. **细胞类型发现**：通过潜在空间探索发现新的细胞亚型
3. **跨数据集转换**：将一个数据集的细胞转换为另一个数据集的风格
4. **质量控制**：检测和修正数据中的异常细胞

这个三阶段训练策略确保了模型既能准确分类细胞类型，又能生成高质量的条件数据，同时保持生物学意义。